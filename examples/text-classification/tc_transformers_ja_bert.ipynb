{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "*Licensed under the MIT License.*\n",
    "\n",
    "# Transformers BERT モデル (PyTorch) による日本語文章のテキスト分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# # path の追加\n",
    "# sys.path.append('../..')\n",
    "\n",
    "from utils_nlp.common.timer import Timer\n",
    "from utils_nlp.common.pytorch_utils import dataloader_from_dataset\n",
    "from utils_nlp.dataset.multinli import load_pandas_df\n",
    "from utils_nlp.models.transformers.sequence_classification import (\n",
    "    Processor, SequenceClassifier)\n",
    "\n",
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "\n",
    "# 表示する列データの幅を変更\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 念のため Transformer Version 確認\n",
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前準備\n",
    "本ノートブックでは日本語対応BERTモデルのファインチューニングと評価を行います。\n",
    "\n",
    "ここでは、[Hugging Face's PyTorch implementation](https://github.com/huggingface/transformers) をラップした [sequence classifier](../../utils_nlp/models/transformers/sequence_classification.py)を利用します。本コードでは、**bert-base-japanase-whole-word-masking** という学習済みモデルを利用します。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# パラメータ\n",
    "DATA_FOLDER = TemporaryDirectory().name\n",
    "CACHE_DIR = TemporaryDirectory().name\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "NUM_GPUS = 2\n",
    "MAX_LEN = 100\n",
    "TRAIN_DATA_FRACTION =1 #サンプリングする場合は割合(<1)を指定\n",
    "TEST_DATA_FRACTION =1 #サンプリングする場合は割合(<1)を指定\n",
    "TRAIN_SIZE = 0.75\n",
    "LABEL_COL = \"label\" # ラベルを含む列名\n",
    "TEXT_COL = \"text\" # テキストを含む列名\n",
    "MODEL_NAMES = [\"bert-base-japanese-whole-word-masking\"] #利用するモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの読み込み\n",
    "[Livedoor ニュースコーパス](https://www.rondhuit.com/download/ldcc-20140209.tar.gz)をダウンロードして利用します。\n",
    "<!-- データのダウンロードと加工手順は [bert-japanese](https://github.com/yoheikikuta/bert-japanese/) を参考にしています。 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"data/\"\n",
    "# if not os.path.exists(data_dir):\n",
    "#     os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "\n",
    "# with tarfile.open('ldcc-20140209.tar.gz', 'r:gz') as tar:\n",
    "#     tar.extractall(path='livedoor')\n",
    "#     tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "# interactive_auth = InteractiveLoginAuthentication(tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\")\n",
    "# ws = Workspace.from_config(auth=interactive_auth)\n",
    "# print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib.request import urlretrieve\n",
    "# import tarfile\n",
    "\n",
    "# text_url = \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\"\n",
    "# file_path = \"./data/ldcc-20140209.tar.gz\"\n",
    "# urlretrieve(text_url, file_path)\n",
    "\n",
    "# mode = \"r:gz\"\n",
    "# tar = tarfile.open(file_path, mode) \n",
    "# tar.extractall(\"./data/livedoor\") \n",
    "# tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('livedoor-corpus-full.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:620: UserWarning: Please install pyarrow>=0.11.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install azureml-dataprep[pandas].\n",
      "  warnings.warn('Please install pyarrow>=0.11.0 for improved performance of to_pandas_dataframe. '\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='livedoor-tabular')\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値を除外します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.isna(df[\"text\"])==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 列名一覧\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の中には自分の式はまだなのに呼ばれてばかり……という「お祝い貧乏」状態の人も多いのではないだろうか？　さらに出席回数を重ねていくと、こんなお願いごとをされることも少なくない。「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」さてそんなとき、独女はどう対応したらいいか？最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。「一晩で3人位の人が添削してくれましたよ。ちなみに自分以外にもそういう人はたくさんいて、その相談サイトには同じように添削をお願いする投稿がいっぱいありました」（由利さん）。ためしに教えてもらったそのサイトをみてみると、確かに「結婚式のスピーチの添削お願いします」という投稿が1000件を超えるくらいあった。めでたい結婚式の影でこんなネットコミュニティがあったとは知らなかった。しかし「事前にお願いされるスピーチなら準備ができるしまだいいですよ。一番嫌なのは何といってもサプライズスピーチ！」と語るのは昨年だけで10万以上お祝いにかかったというお祝い貧乏独女の薫さん（35歳）「私は基本的に人前で話すのが苦手なんですよ。だからいきなり指名されるとしどろもどろになって何もいえなくなる。そうすると自己嫌悪に陥って終わった後でもまったく楽しめなくなりますね」サプライズスピーチのメリットとしては、準備していない状態なので、フランクな本音をしゃべってもらえるという楽しさがあるようだ。しかしそれも上手に対応できる人ならいいが、苦手な人の場合だと「フランク」ではなく「しどろもどろ」になる危険性大。ちなみにプロの司会者の場合、本当のサプライズではなく式の最中に「のちほどサプライズスピーチとしてご指名させてい...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ネットで断ち切れない元カレとの縁携帯電話が普及する以前、恋人への連絡ツールは一般電話が普通だった。恋人と別れたら、手帳に書かれた相手の連絡先を涙ながらに消す。そうすれば、いつしか縁は切れていったものである。しかし現在は、携帯電話がありメールがあり、インターネットを開けば、ブログで相手の晩飯までわかってしまう赤裸々なご時世。切っても切れない元カレとの縁に独女たちは何を思うのであろうか？「5年前に別れた彼からメールが届いてビックリしました」とは尚美さん（36歳）「彼の浮気が原因で別れたのですが、現在は独り身らしいことが書いてありました。ただ、私には婚約間近の恋人がいるのでスルー。もし自分に相手がいなかったら、復活愛はあったかも。出会いの機会が少ない独女にとって、いい時代と言えるのでは？」彼と交際していた当時、尚美さんは実家に住んでいた。もしもメールも携帯電話もない時代だったら、恐らく彼からの連絡はあり得なかっただろう。一方、美加子さん（38歳）は「一般電話だけの時代のほうが、縁を切りにくかったですよ」という。「今はメモリ頼りになっている分、電話番号やメールアドレスを消去してしまえばそれまでってところがありますからね。ずるずる引きずろうと思えば引きずれるし、切ろうと思えば切れる。ひと昔前は彼の電話番号を暗記していたものです。受話器を上げたり戻したり……気持ちを断つのが難しかったなぁ」知恵さん（34歳）も同意見だ。「情報は自分が情報網を使えば入ってくるが　自分次第でシャットアウトできるもの。だけど私は、“別れた彼と絶縁すべき”とは思っていません。心が癒されるまでの期間は連絡を断ちきり、それ以降はメールを送るなどして、友達関係に戻ることが多いですね」オール・オア・ナッシングだった以前に比べ、今は縁を切る、友人に戻る、メル友関係を続けるなど、別れた後の関係性を選択できるようになった。未練が残っているうちは辛いが、ツールを上手く使えばメリットを得られることもあるだろう。ただし、落とし穴もある。最後に、律子さん（35歳）のトホホな話を紹介。「10年前につきあっていた元彼とは、節目節目にメールをしています。“マイミク”で日記にコメントを書き込んだりもするし、年賀状もやりとりする仲。元彼はすでに結婚して子どもが二人いるんですね。最近はすっかり中年太りしてきてマイホームパパって感...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>相次ぐ芸能人の“すっぴん”披露　その時、独女の心境は？「男性はやっぱり、女性の“すっぴん”が大好きなんですかね」と不満そうに話すのは、出版関係で働く香さん（仮名／31歳）。というのも、最近ブログにすっぴん写真を掲載する芸能人が多く、それがニュースになり話題になることがあるからだ。今年に入ってから、“すっぴん”をブログで披露した芸能人は、小倉優子、安倍なつみ、モーニング娘。の田中れいな、優木まおみ、仲里依紗など、年齢も活躍しているジャンルも様々。私生活をリアルタイムに発信できるブログだからこそ、皆それぞれにリラックスした表情で自分のすっぴんを公開している。ファンにとっては、好きな芸能人の素顔が垣間見れる嬉しいサービスなのだろう。では、なぜ芸能人のすっぴん顔披露に、彼女は疑問を抱いたのだろうか。「私のひがみだと言う事は重々承知なんですけど、“随分自分に自信があるんだな”って、素直にその美しさを認める事が出来なくて…」と話す香さん。「コメントに“すっぴんでもかわいい！”とか、“メイクしなくても全然OK！”とか賞賛ばかりが並ぶのを見越して、すっぴん写真を公開してるんだなって思うと何か複雑ですね」と付け加えた。本来ファンサービスである為のすっぴん披露を、「話題を呼ぶ為や、コメントで褒められたいから」行っているのでは？　と、独女はつい“ナナメ”に見てしまう様だ。また、メーカーで営業をしている裕美さん（仮名／32歳）は「男性の“すっぴん幻想”には参りますね。そりゃ素顔がキレイならば私だってすっぴんで出社しますよ。でも、毎日少しでもキレイになりたいと一生懸命メイクしている努力も認めて欲しいな」と独女なりの乙女心を明かしてくれた。「10代や20代前半の若い女の子がすっぴんを載せているのは、“ああ、やっぱり可愛いな”と心から思えるんですけど、私と同年代の人が披露していると自分のすっぴんと比べてゲンナリします」と、美しい芸能人すっぴんを見た後に独女達は人知れず傷ついているのである。さて、芸能人のすっぴん披露、実際に男性の評判はどうなのだろうか。アパレル企業に勤める雄介さん（仮名／34歳）は「個人的に女性のメイクした顔に魅力を感じないから、すっぴんを見るとすごく可愛いと思う」と賛成派。一方、IT企業で働く徹さん（仮名／28歳）は「人によるけど、何でわざわざブログに載せるんだろうとは...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ムダな抵抗！？ 加齢の現実ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「そげる→たわむ→外に流れる」という。バストの変化はすでに20代から始まり、20代にして「たわむ」になっている人もいる。そして、元に戻った人は一人もいない。さらに、体の各部位の20代〜50代までの変化をみると、ウエストとお腹の変化が最も大きく、お腹はバストと同じ大きさになっている。これは、４月に開催されたワコール人間科学研究所の記者発表「からだのエイジング（加齢による体型変化）について一定の法則を発見」での内容の一部。延べ4万人分の経年変化の数値を集計・分析したデータとともに、写真や映像で説明させるので説得力は抜群だ。現実を直視させられた後に、体型変化の少ない人達の身体的特徴や日常の行動・意識を紹介。その主な内容は、日頃から体を動かし、姿勢をチェック、下着は必ず試着してフィット感を確かめるというもの。そして、パネルディスカッションでは、歩幅の広い歩き方を１年間続ける実験に参加した人が、背筋が伸び、脂肪が落ちたという結果などが紹介されていた。興味は尽きず、知人たちに内容を伝えるとさまざまな意見や経験が聞けた。「ずっと計測されているから、体型変化の少ない人はスポーツをしてたのでは？」という疑問もあったが、この回答は、「運動を一生懸命しているというより日常生活を気をつけている印象が強い。そして、ダイエットはあまりしたことがない」とのこと。「叔母もそんなことを言っていた」と言うのはＹ子。60歳代の叔母さんが友人たちと温泉旅行に行ったとき、「バストの変化が少ないとほめられた」と喜んでいたので、バストのケア方法を尋ねたそうだ。「叔母はブラジャーを常に着用し、購入時は必ず計測して試着している。一方、友人達は『苦しい』からと家ではブラジャーをしないこともあるらしい」。それを聞いて以来、Ｙ子は下着を買うときには試着はもちろん、計ってもらうようにしている。「私も歩いてやせた」と話すのは、腰痛に悩まされていたＫ子。医師に筋力の低下を指摘されて、駅までの自転車を止めて、片道30分の道のりを毎日往復歩くことに。筋力をつけるために始めたことで体全体が引き締まり、結果として減量にも成功した。「でも、スポーツすればしまるよね」と言うＡ子は、不摂生がたたって気になり始めたウエスト回りをスポーツクラブに通...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>税金を払うのは私たちなんですけど！6月から支給される子ども手当だが、当初は子ども一人当たり月額2万6000円が支給されるはずだった。ところが、初年度は半額支給となり、さらに2011年度以降も子ども一人当たり月額2万6000円の支給は見送られそうだ。先日は在日外国人男性がタイで養子縁組をしたと称する554人分の子ども手当を申請しようとして市から却下されたニュースが報じられたが、悪い人間がちょっと考えれば簡単に不正ができるような不備だらけの子ども手当って、一体どうなっているの？ と支給されない側の独女からも疑問の声が聞こえる。現在独身の由梨さんは、「私立の幼稚園にベンツで送り迎えをしているような家にどうして子ども手当が必要なの？」と一律支給にはどうしても納得できないと訴える。「子ども手当はフランスの真似をしたと聞いていますけど、フランスでは子ども手当は“家族手当”といい所得制限はありません。でも家族手当が貰えるのは第2子からで20歳まで支給され、３人目からは割増の家族手当が貰えるそうです。子ども手当が少子化対策を目的にしたものなら、フランスのように2人目から手当を出すべきではないですか？」一律支給だけをフランスの真似をするのはおかしいという。それに少子化対策と言われながら、子ども手当を当てにして出産しようという声は聞かない。「政権交代をすればなくなるかもしれない手当を期待して、今から結婚してもすぐに妊娠するとは限らないし、無事出産の暁には子ども手当は廃止されているかもしれないですよね」その可能性もなきにしもあらずだ。子ども手当の使い道について子どものいる主婦に聞くと、将来の教育費のために貯蓄に回すという人が多かった。それについても、「子どもが欲しくてもできなかった家庭がその費用を負担するのはとてもお気の毒な気がします。それに本当に子どものために使われるのならいいのですが、親がギャンブルに使ったり、親の遊興費に使われるために私たちの税金を使ってほしくないですね」と由梨さん。バツイチの綾さんは、「子どものいない夫婦も、独身も、働いて税金を納めることで次世代を担う子どもたちを育てることに貢献する。それが子ども手当だと思っていましたが、子どものいる家庭にいくはずのお金がどんどん減らされ、それがどこへ行くのかわからないし、申請書の偽装で、私たちの税金が外国人の子どものとこ...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の中には自分の式はまだなのに呼ばれてばかり……という「お祝い貧乏」状態の人も多いのではないだろうか？　さらに出席回数を重ねていくと、こんなお願いごとをされることも少なくない。「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」さてそんなとき、独女はどう対応したらいいか？最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。「一晩で3人位の人が添削してくれましたよ。ちなみに自分以外にもそういう人はたくさんいて、その相談サイトには同じように添削をお願いする投稿がいっぱいありました」（由利さん）。ためしに教えてもらったそのサイトをみてみると、確かに「結婚式のスピーチの添削お願いします」という投稿が1000件を超えるくらいあった。めでたい結婚式の影でこんなネットコミュニティがあったとは知らなかった。しかし「事前にお願いされるスピーチなら準備ができるしまだいいですよ。一番嫌なのは何といってもサプライズスピーチ！」と語るのは昨年だけで10万以上お祝いにかかったというお祝い貧乏独女の薫さん（35歳）「私は基本的に人前で話すのが苦手なんですよ。だからいきなり指名されるとしどろもどろになって何もいえなくなる。そうすると自己嫌悪に陥って終わった後でもまったく楽しめなくなりますね」サプライズスピーチのメリットとしては、準備していない状態なので、フランクな本音をしゃべってもらえるという楽しさがあるようだ。しかしそれも上手に対応できる人ならいいが、苦手な人の場合だと「フランク」ではなく「しどろもどろ」になる危険性大。ちなみにプロの司会者の場合、本当のサプライズではなく式の最中に「のちほどサプライズスピーチとしてご指名させてい...   \n",
       "1  ネットで断ち切れない元カレとの縁携帯電話が普及する以前、恋人への連絡ツールは一般電話が普通だった。恋人と別れたら、手帳に書かれた相手の連絡先を涙ながらに消す。そうすれば、いつしか縁は切れていったものである。しかし現在は、携帯電話がありメールがあり、インターネットを開けば、ブログで相手の晩飯までわかってしまう赤裸々なご時世。切っても切れない元カレとの縁に独女たちは何を思うのであろうか？「5年前に別れた彼からメールが届いてビックリしました」とは尚美さん（36歳）「彼の浮気が原因で別れたのですが、現在は独り身らしいことが書いてありました。ただ、私には婚約間近の恋人がいるのでスルー。もし自分に相手がいなかったら、復活愛はあったかも。出会いの機会が少ない独女にとって、いい時代と言えるのでは？」彼と交際していた当時、尚美さんは実家に住んでいた。もしもメールも携帯電話もない時代だったら、恐らく彼からの連絡はあり得なかっただろう。一方、美加子さん（38歳）は「一般電話だけの時代のほうが、縁を切りにくかったですよ」という。「今はメモリ頼りになっている分、電話番号やメールアドレスを消去してしまえばそれまでってところがありますからね。ずるずる引きずろうと思えば引きずれるし、切ろうと思えば切れる。ひと昔前は彼の電話番号を暗記していたものです。受話器を上げたり戻したり……気持ちを断つのが難しかったなぁ」知恵さん（34歳）も同意見だ。「情報は自分が情報網を使えば入ってくるが　自分次第でシャットアウトできるもの。だけど私は、“別れた彼と絶縁すべき”とは思っていません。心が癒されるまでの期間は連絡を断ちきり、それ以降はメールを送るなどして、友達関係に戻ることが多いですね」オール・オア・ナッシングだった以前に比べ、今は縁を切る、友人に戻る、メル友関係を続けるなど、別れた後の関係性を選択できるようになった。未練が残っているうちは辛いが、ツールを上手く使えばメリットを得られることもあるだろう。ただし、落とし穴もある。最後に、律子さん（35歳）のトホホな話を紹介。「10年前につきあっていた元彼とは、節目節目にメールをしています。“マイミク”で日記にコメントを書き込んだりもするし、年賀状もやりとりする仲。元彼はすでに結婚して子どもが二人いるんですね。最近はすっかり中年太りしてきてマイホームパパって感...   \n",
       "2  相次ぐ芸能人の“すっぴん”披露　その時、独女の心境は？「男性はやっぱり、女性の“すっぴん”が大好きなんですかね」と不満そうに話すのは、出版関係で働く香さん（仮名／31歳）。というのも、最近ブログにすっぴん写真を掲載する芸能人が多く、それがニュースになり話題になることがあるからだ。今年に入ってから、“すっぴん”をブログで披露した芸能人は、小倉優子、安倍なつみ、モーニング娘。の田中れいな、優木まおみ、仲里依紗など、年齢も活躍しているジャンルも様々。私生活をリアルタイムに発信できるブログだからこそ、皆それぞれにリラックスした表情で自分のすっぴんを公開している。ファンにとっては、好きな芸能人の素顔が垣間見れる嬉しいサービスなのだろう。では、なぜ芸能人のすっぴん顔披露に、彼女は疑問を抱いたのだろうか。「私のひがみだと言う事は重々承知なんですけど、“随分自分に自信があるんだな”って、素直にその美しさを認める事が出来なくて…」と話す香さん。「コメントに“すっぴんでもかわいい！”とか、“メイクしなくても全然OK！”とか賞賛ばかりが並ぶのを見越して、すっぴん写真を公開してるんだなって思うと何か複雑ですね」と付け加えた。本来ファンサービスである為のすっぴん披露を、「話題を呼ぶ為や、コメントで褒められたいから」行っているのでは？　と、独女はつい“ナナメ”に見てしまう様だ。また、メーカーで営業をしている裕美さん（仮名／32歳）は「男性の“すっぴん幻想”には参りますね。そりゃ素顔がキレイならば私だってすっぴんで出社しますよ。でも、毎日少しでもキレイになりたいと一生懸命メイクしている努力も認めて欲しいな」と独女なりの乙女心を明かしてくれた。「10代や20代前半の若い女の子がすっぴんを載せているのは、“ああ、やっぱり可愛いな”と心から思えるんですけど、私と同年代の人が披露していると自分のすっぴんと比べてゲンナリします」と、美しい芸能人すっぴんを見た後に独女達は人知れず傷ついているのである。さて、芸能人のすっぴん披露、実際に男性の評判はどうなのだろうか。アパレル企業に勤める雄介さん（仮名／34歳）は「個人的に女性のメイクした顔に魅力を感じないから、すっぴんを見るとすごく可愛いと思う」と賛成派。一方、IT企業で働く徹さん（仮名／28歳）は「人によるけど、何でわざわざブログに載せるんだろうとは...   \n",
       "3  ムダな抵抗！？ 加齢の現実ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「そげる→たわむ→外に流れる」という。バストの変化はすでに20代から始まり、20代にして「たわむ」になっている人もいる。そして、元に戻った人は一人もいない。さらに、体の各部位の20代〜50代までの変化をみると、ウエストとお腹の変化が最も大きく、お腹はバストと同じ大きさになっている。これは、４月に開催されたワコール人間科学研究所の記者発表「からだのエイジング（加齢による体型変化）について一定の法則を発見」での内容の一部。延べ4万人分の経年変化の数値を集計・分析したデータとともに、写真や映像で説明させるので説得力は抜群だ。現実を直視させられた後に、体型変化の少ない人達の身体的特徴や日常の行動・意識を紹介。その主な内容は、日頃から体を動かし、姿勢をチェック、下着は必ず試着してフィット感を確かめるというもの。そして、パネルディスカッションでは、歩幅の広い歩き方を１年間続ける実験に参加した人が、背筋が伸び、脂肪が落ちたという結果などが紹介されていた。興味は尽きず、知人たちに内容を伝えるとさまざまな意見や経験が聞けた。「ずっと計測されているから、体型変化の少ない人はスポーツをしてたのでは？」という疑問もあったが、この回答は、「運動を一生懸命しているというより日常生活を気をつけている印象が強い。そして、ダイエットはあまりしたことがない」とのこと。「叔母もそんなことを言っていた」と言うのはＹ子。60歳代の叔母さんが友人たちと温泉旅行に行ったとき、「バストの変化が少ないとほめられた」と喜んでいたので、バストのケア方法を尋ねたそうだ。「叔母はブラジャーを常に着用し、購入時は必ず計測して試着している。一方、友人達は『苦しい』からと家ではブラジャーをしないこともあるらしい」。それを聞いて以来、Ｙ子は下着を買うときには試着はもちろん、計ってもらうようにしている。「私も歩いてやせた」と話すのは、腰痛に悩まされていたＫ子。医師に筋力の低下を指摘されて、駅までの自転車を止めて、片道30分の道のりを毎日往復歩くことに。筋力をつけるために始めたことで体全体が引き締まり、結果として減量にも成功した。「でも、スポーツすればしまるよね」と言うＡ子は、不摂生がたたって気になり始めたウエスト回りをスポーツクラブに通...   \n",
       "4  税金を払うのは私たちなんですけど！6月から支給される子ども手当だが、当初は子ども一人当たり月額2万6000円が支給されるはずだった。ところが、初年度は半額支給となり、さらに2011年度以降も子ども一人当たり月額2万6000円の支給は見送られそうだ。先日は在日外国人男性がタイで養子縁組をしたと称する554人分の子ども手当を申請しようとして市から却下されたニュースが報じられたが、悪い人間がちょっと考えれば簡単に不正ができるような不備だらけの子ども手当って、一体どうなっているの？ と支給されない側の独女からも疑問の声が聞こえる。現在独身の由梨さんは、「私立の幼稚園にベンツで送り迎えをしているような家にどうして子ども手当が必要なの？」と一律支給にはどうしても納得できないと訴える。「子ども手当はフランスの真似をしたと聞いていますけど、フランスでは子ども手当は“家族手当”といい所得制限はありません。でも家族手当が貰えるのは第2子からで20歳まで支給され、３人目からは割増の家族手当が貰えるそうです。子ども手当が少子化対策を目的にしたものなら、フランスのように2人目から手当を出すべきではないですか？」一律支給だけをフランスの真似をするのはおかしいという。それに少子化対策と言われながら、子ども手当を当てにして出産しようという声は聞かない。「政権交代をすればなくなるかもしれない手当を期待して、今から結婚してもすぐに妊娠するとは限らないし、無事出産の暁には子ども手当は廃止されているかもしれないですよね」その可能性もなきにしもあらずだ。子ども手当の使い道について子どものいる主婦に聞くと、将来の教育費のために貯蓄に回すという人が多かった。それについても、「子どもが欲しくてもできなかった家庭がその費用を負担するのはとてもお気の毒な気がします。それに本当に子どものために使われるのならいいのですが、親がギャンブルに使ったり、親の遊興費に使われるために私たちの税金を使ってほしくないですね」と由梨さん。バツイチの綾さんは、「子どものいない夫婦も、独身も、働いて税金を納めることで次世代を担う子どもたちを育てることに貢献する。それが子ども手当だと思っていましたが、子どものいる家庭にいくはずのお金がどんどん減らされ、それがどこへ行くのかわからないし、申請書の偽装で、私たちの税金が外国人の子どものとこ...   \n",
       "\n",
       "            label  \n",
       "0  dokujo-tsushin  \n",
       "1  dokujo-tsushin  \n",
       "2  dokujo-tsushin  \n",
       "3  dokujo-tsushin  \n",
       "4  dokujo-tsushin  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本データセットでは9種類のラベルに分類されます。それぞれのデータ数を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c9463d128>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(df[LABEL_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを学習用、テスト用に分割します。またラベル名をエンコーディングしてBERTで扱えるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# データ分割\n",
    "df_train, df_test = train_test_split(df, train_size = TRAIN_SIZE, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 必要であればサンプリング\n",
    "# df_train = df_train.sample(frac=TRAIN_DATA_FRACTION).reset_index(drop=True)\n",
    "# df_test = df_test.sample(frac=TEST_DATA_FRACTION).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# ラベルのエンコーディング\n",
    "label_encoder = LabelEncoder()\n",
    "df_train[LABEL_COL] = label_encoder.fit_transform(df_train[LABEL_COL])\n",
    "df_test[LABEL_COL] = label_encoder.transform(df_test[LABEL_COL])\n",
    "\n",
    "num_labels = len(np.unique(df_train[LABEL_COL]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 9\n",
      "Number of training examples: 5525\n",
      "Number of testing examples: 1842\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique labels: {}\".format(num_labels))\n",
    "print(\"Number of training examples: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of testing examples: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの選択\n",
    "\n",
    "[Hugging Face](https://github.com/huggingface/transformers) には学習済みモデルが公開されており簡単に利用することができます。テキスト分類で利用できるモデル一覧を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>モデル名</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-large-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-large-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert-base-multilingual-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert-base-chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert-base-german-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert-large-uncased-whole-word-masking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert-large-cased-whole-word-masking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert-large-uncased-whole-word-masking-finetuned-squad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert-large-cased-whole-word-masking-finetuned-squad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert-base-cased-finetuned-mrpc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert-base-german-dbmdz-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert-base-german-dbmdz-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bert-base-japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bert-base-japanese-whole-word-masking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bert-base-japanese-char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert-base-japanese-char-whole-word-masking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bert-base-finnish-cased-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bert-base-finnish-uncased-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bert-base-dutch-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>roberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>roberta-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>roberta-large-mnli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>distilroberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>roberta-base-openai-detector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>roberta-large-openai-detector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>xlnet-base-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>xlnet-large-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>distilbert-base-uncased-distilled-squad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>distilbert-base-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>distilbert-base-cased-distilled-squad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>distilbert-base-german-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>distilbert-base-multilingual-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>albert-base-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>albert-large-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>albert-xlarge-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>albert-xxlarge-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>albert-base-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>albert-large-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>albert-xlarge-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>albert-xxlarge-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     モデル名\n",
       "0                                       bert-base-uncased\n",
       "1                                      bert-large-uncased\n",
       "2                                         bert-base-cased\n",
       "3                                        bert-large-cased\n",
       "4                          bert-base-multilingual-uncased\n",
       "5                            bert-base-multilingual-cased\n",
       "6                                       bert-base-chinese\n",
       "7                                  bert-base-german-cased\n",
       "8                   bert-large-uncased-whole-word-masking\n",
       "9                     bert-large-cased-whole-word-masking\n",
       "10  bert-large-uncased-whole-word-masking-finetuned-squad\n",
       "11    bert-large-cased-whole-word-masking-finetuned-squad\n",
       "12                         bert-base-cased-finetuned-mrpc\n",
       "13                           bert-base-german-dbmdz-cased\n",
       "14                         bert-base-german-dbmdz-uncased\n",
       "15                                     bert-base-japanese\n",
       "16                  bert-base-japanese-whole-word-masking\n",
       "17                                bert-base-japanese-char\n",
       "18             bert-base-japanese-char-whole-word-masking\n",
       "19                             bert-base-finnish-cased-v1\n",
       "20                           bert-base-finnish-uncased-v1\n",
       "21                                  bert-base-dutch-cased\n",
       "22                                           roberta-base\n",
       "23                                          roberta-large\n",
       "24                                     roberta-large-mnli\n",
       "25                                     distilroberta-base\n",
       "26                           roberta-base-openai-detector\n",
       "27                          roberta-large-openai-detector\n",
       "28                                       xlnet-base-cased\n",
       "29                                      xlnet-large-cased\n",
       "30                                distilbert-base-uncased\n",
       "31                distilbert-base-uncased-distilled-squad\n",
       "32                                  distilbert-base-cased\n",
       "33                  distilbert-base-cased-distilled-squad\n",
       "34                           distilbert-base-german-cased\n",
       "35                     distilbert-base-multilingual-cased\n",
       "36        distilbert-base-uncased-finetuned-sst-2-english\n",
       "37                                         albert-base-v1\n",
       "38                                        albert-large-v1\n",
       "39                                       albert-xlarge-v1\n",
       "40                                      albert-xxlarge-v1\n",
       "41                                         albert-base-v2\n",
       "42                                        albert-large-v2\n",
       "43                                       albert-xlarge-v2\n",
       "44                                      albert-xxlarge-v2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"モデル名\": SequenceClassifier.list_supported_models()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファインチューニング\n",
    "\n",
    "本コードで実装されているラッパーを利用することで簡単にファインチューニングが実行できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bert-base-japanese-whole-word-masking']\n"
     ]
    }
   ],
   "source": [
    "# 利用するモデル名\n",
    "print(MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ前処理、ファインチューニング、テストデータの予測、評価をステップを実施していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4beb5dbb68ba4ab98164916b8c58bad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=257706, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "model_name = MODEL_NAMES[0]\n",
    "\n",
    "# 前処理\n",
    "processor = Processor(\n",
    "    model_name=model_name,\n",
    "    to_lower=model_name.endswith(\"uncased\"),\n",
    "    cache_dir=CACHE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = processor.dataset_from_dataframe(\n",
    "    df_train, TEXT_COL, LABEL_COL, max_len=MAX_LEN\n",
    ")\n",
    "train_dataloader = dataloader_from_dataset(\n",
    "    train_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS, shuffle=True\n",
    ")\n",
    "test_dataset = processor.dataset_from_dataframe(\n",
    "    df_test, TEXT_COL, LABEL_COL, max_len=MAX_LEN\n",
    ")\n",
    "test_dataloader = dataloader_from_dataset(\n",
    "    test_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c7030641f94576b823b970ff459d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=383, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6c4228bb064c8ab5c01c8191994dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=445021143, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ファインチューニング\n",
    "classifier = SequenceClassifier(\n",
    "    model_name=model_name, num_labels=num_labels, cache_dir=CACHE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    classifier.fit(\n",
    "        train_dataloader, num_epochs=NUM_EPOCHS, num_gpus=NUM_GPUS, verbose=False,\n",
    "    )\n",
    "train_time = t.interval / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの予測\n",
    "preds = classifier.predict(test_dataloader, num_gpus=NUM_GPUS, verbose=False)\n",
    "\n",
    "# 評価\n",
    "accuracy = accuracy_score(df_test[LABEL_COL], preds)\n",
    "class_report = classification_report(\n",
    "    df_test[LABEL_COL], preds, target_names=label_encoder.classes_, output_dict=True\n",
    ")\n",
    "\n",
    "# 結果の保存\n",
    "results[model_name] = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"f1-score\": class_report[\"macro avg\"][\"f1-score\"],\n",
    "    \"time(hrs)\": train_time,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_test[LABEL_COL] = label_encoder.inverse_transform(df_test[LABEL_COL])\n",
    "df_test[\"pred\"] = label_encoder.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>インタビュ—：ティム・ディケイ（ピーター・バーク役）——犯罪ドラマが色々ある中で、この『ホワイト・カラー』はとりわけ人気を集めていますが、その人気の秘密はどこにあると思いますか？ティム・ディケイ：犯罪ドラマというのは普通、主人公達が家に帰るところまで見せないで、犯罪そのものについての物語だと思うんだ。でも、僕らの番組は、それよりもむしろ人間関係について描いたものである、ということが大きな違いだと思うんだよね。だから何が盗まれたとか取られたみたいなことはあまりに重要ではない。視聴者にとって大事なのは、ピーター（・バーク）とニール（・キャフリー）の人間関係であり、ふたりがどのようにして悪者を見付けていくのかという部分なんだ。それに僕自身、俳優としても、犯罪について描くよりも、人間関係について扱うほうが、ずっと面白いからね。——ピーターとニールの相性がすごく良いと思うのですが、話し合いなどをしてこの作品に取り組んだのですか？父親と息子であったり、兄弟的であったり、すごく家族的なところがあるので、良いと思うのですが。ティム・ディケイ：うん、確かにそうだね。だけど、ふたりで改めて話し合ったことはないんだ。まず、彼が先に役に決まっていたんだけど、プロデューサーが僕らの相性を見るために、僕は彼と脚本の読み合わせをしたんだよね。それで読み合わせを始めたその瞬間に、僕らはお互いふたりの関係性が特別なものだというのが分かったんだ。即座にね。それで番組を撮り続けていく過程で、その時々の物語に応じて、ふたりの関係性について話すことはあったけど、全体的な関係性について話し合ったりしたことはないんだ。なぜなら始まった瞬間から、ティム（・ディケイ）とマット（・ボマー）がお互いを好きだということはすぐに分かったし、それにピーターとニールもお互いが好きなんだ。ふたりは、もしかしたら信頼し合ってはいないかもしれない。それでも、お互いが好きであることは確かなんだ。だからこの番組にとっては、ふたりがその根底において、お互い愛があり、大事に思っているということを描き続けることが非常に重要だと思うんだよね。例えば、銃弾がニールに飛んできたら、絶対にピーターは飛び込んでニールを守ろうとすると思うんだ。そして、ニールもピーターのために同じことをすると思うよ。——あなたの演じているピーターというキャラクター...</td>\n",
       "      <td>movie-enter</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "3162  インタビュ—：ティム・ディケイ（ピーター・バーク役）——犯罪ドラマが色々ある中で、この『ホワイト・カラー』はとりわけ人気を集めていますが、その人気の秘密はどこにあると思いますか？ティム・ディケイ：犯罪ドラマというのは普通、主人公達が家に帰るところまで見せないで、犯罪そのものについての物語だと思うんだ。でも、僕らの番組は、それよりもむしろ人間関係について描いたものである、ということが大きな違いだと思うんだよね。だから何が盗まれたとか取られたみたいなことはあまりに重要ではない。視聴者にとって大事なのは、ピーター（・バーク）とニール（・キャフリー）の人間関係であり、ふたりがどのようにして悪者を見付けていくのかという部分なんだ。それに僕自身、俳優としても、犯罪について描くよりも、人間関係について扱うほうが、ずっと面白いからね。——ピーターとニールの相性がすごく良いと思うのですが、話し合いなどをしてこの作品に取り組んだのですか？父親と息子であったり、兄弟的であったり、すごく家族的なところがあるので、良いと思うのですが。ティム・ディケイ：うん、確かにそうだね。だけど、ふたりで改めて話し合ったことはないんだ。まず、彼が先に役に決まっていたんだけど、プロデューサーが僕らの相性を見るために、僕は彼と脚本の読み合わせをしたんだよね。それで読み合わせを始めたその瞬間に、僕らはお互いふたりの関係性が特別なものだというのが分かったんだ。即座にね。それで番組を撮り続けていく過程で、その時々の物語に応じて、ふたりの関係性について話すことはあったけど、全体的な関係性について話し合ったりしたことはないんだ。なぜなら始まった瞬間から、ティム（・ディケイ）とマット（・ボマー）がお互いを好きだということはすぐに分かったし、それにピーターとニールもお互いが好きなんだ。ふたりは、もしかしたら信頼し合ってはいないかもしれない。それでも、お互いが好きであることは確かなんだ。だからこの番組にとっては、ふたりがその根底において、お互い愛があり、大事に思っているということを描き続けることが非常に重要だと思うんだよね。例えば、銃弾がニールに飛んできたら、絶対にピーターは飛び込んでニールを守ろうとすると思うんだ。そして、ニールもピーターのために同じことをすると思うよ。——あなたの演じているピーターというキャラクター...   \n",
       "\n",
       "            label         pred  \n",
       "3162  movie-enter  movie-enter  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価\n",
    "\n",
    "精度、F1-スコア、学習時間を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert-base-japanese-whole-word-masking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.916938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.912887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time(hrs)</th>\n",
       "      <td>0.019315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bert-base-japanese-whole-word-masking\n",
       "accuracy                                0.916938\n",
       "f1-score                                0.912887\n",
       "time(hrs)                               0.019315"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.9169381107491856,
       "encoder": "json",
       "name": "accuracy",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "accuracy"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.9128866437280547,
       "encoder": "json",
       "name": "f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "f1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for testing\n",
    "sb.glue(\"accuracy\", df_results.iloc[0, :].mean())\n",
    "sb.glue(\"f1\", df_results.iloc[1, :].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_gpu)",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
